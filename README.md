# Supervised-Learning---Decision-Tree-prediction-and-visualization

### Decision Tree Algorithm

1. Place the best attribute of our dataset at the root of the tree.
2. Split the training set into subsets. Subsets should be made in such a way that each subset contains data with the same value      for an attribute.
3. Repeat step 1 and step 2 on each subset until you find leaf nodes in all the branches of the tree.

#### Decision Tree Training
Now we fit Decision tree algorithm on training data, predicting labels for validation dataset and printing the accuracy of the model using various parameters.

### Terms used in code :

Gini index and information gain both of these methods are used to select from the n attributes of the dataset which attribute would be placed at the root node or the internal node.

1) Gini index
2) Entropy
3) Information Gain
4) Accuracy score
5) Confusion Matrix
